\clearpage
\chapter{Literature Review}


\section{Techniques in Activity Recognition}
Recent advancements in recognising human actions in videos have significantly
impacted various fields, ranging from the medical sector to surveillance
systems, \cite{3DhumanActionDetectionForHealthCareSystems},
\cite{HumanActivityRecognitionSecurityAndMonitoring}. Particularly noteworthy is
its application in developing an AI-based skateboard trick classifier, an area
that has seen limited research.


\section{Preprocessing techniques}

\section{Advancements in Skateboard Trick Classification}

\paragraph{}
In the emergent field of skateboard trick classification, leveraging activity
recognition techniques from a video has led to two primary methodologies among
researchers. The first technique involves utilising signals obtained from
skateboard-mounted accelerometers or signals artificially generated based on the
findings of prior studies. These signals are then fed into a study-dependent
model for classification, as outlined in
\cite{skateboardClassificationTransferLearningPipelinesAccelermetry} and
\cite{skateboardTrickClassifierUsingAccelerometryAndML}. The second approach
employs computer vision techniques, leveraging video footage of skateboard
tricks to train and refine models for accurate trick identification, as depicted
by the studies \cite{skatePaper1} and \cite{SkateboardAIPaper}. 

\subsection{Accelerometry approach}
\paragraph{}
The study by Abdullah et al (2021)
\cite{skateboardClassificationTransferLearningPipelinesAccelermetry}, makes use
of a custom dataset comprising of six skateboard tricks most commonly executed
in competitive events. Amateur skateboarders performed each trick five times on
a modified skateboard equipped with an Inertial Measurement Unit (IMU) to record
the signals produced. The researchers capture six signals for each trick,
including linear accelerations along the x, y, and z axes (aX, aY, aZ) and
angular accelerations along the same axes (gX, gY, gZ). They then opt for the
unique approach of concatenating all six signals onto a single image
corresponding to one trick, employing two input image transformations: raw data
(RAW) and Continuous Wavelet Transform (CWT). 
\paragraph{}
With the application of six transfer learning models on this data, Abdullah et
al. \cite{skateboardClassificationTransferLearningPipelinesAccelermetry} reports
exceptionally high accuracies, achieving a 100\% test accuracy over multiple
models. While these results are remarkable, very high levels of accuracy are
rare in ML applications and are typically associated with models that may be
overfitting the data. Recognising the rarity of such high accuracies, this study
will take these findings into consideration and efforts will be made to ensure a
robust model by employing techniques to avoid overfitting such as early-stopping
and the use of a diverse dataset \cite{AnOverviewOfOverfittingAndItsSolutions}.


% the results show that RAW and CWT input
% images on MobileNet, MobileNetV2 and ResNet101 models achieved favourable
% accuracy. However, the CWT-MobileNet-Optimised SVM pipeline was deemed the best
% due to its reduction in computational time.

\paragraph{}
The study by Corrêa et al (2017)
\cite{skateboardTrickClassifierUsingAccelerometryAndML}, obtained their sample
data by artificially generating 543 signals based on prior research, utilising
tools such as MATLAB 2015 and Signal Processing Toolbox. These signals were then
categorised into five distinct classes representing different skateboard tricks,
each with various samples ranging from 30 to 50 per class, across three axes (X,
Y and Z). This study developed and validated individual Artificial Neural
Networks (ANNs) for each axis, as well as the combination of the three: ANN XYZ,
displaying the potential of Neural Networks to categorise multidimensional
skateboard tricks. The ANNs are all multilayer feed-forward neural networks
(MFFNNs), structured into three distinct layers. They feature an input layer
with 82 neurons, a hidden layer, comprised of 23 neurons utilising a tan-sigmoid
transfer function and an output layer consisting of 5 neurons with a softmax
function. Finally, the study achieved high accuracies, with ANNs X, Y and Z
achieving accuracies of 94.8\%, 96.7\% and 98.7\%, respectively, while the
combined ANN XYZ achieved an accuracy of 92.8\%. 


\subsection{Computer Vision Approach}
\paragraph{}
The paper by Shapiee et al (2020) \cite{skatePaper1} leverages a custom data set
comprising videos capturing the execution of five distinct skateboard tricks,
each attempted five times. Each video spans two to three seconds, yielding a
total of 750 images by extracting 30 frames per video. This study made use of
data augmentation techniques to expand their dataset further. Consequently, they
introduced an additional 2,250 images, achieving 3,000 images in their data set.
On the other hand, Chen (2023) \cite{SkateboardAIPaper} compiled a comprehensive
data set by collecting videos from multiple platforms, including YouTube,
Twitter and Instagram. Furthermore, Chen trained the model using 15 fundamental
tricks commonly observed in competitive settings. The researcher collected 50
videos per trick, summing up to a total number of 750 videos. Of these, 45
videos per trick were allocated for training, and the remaining 5 were reserved
for validation. 

\paragraph{}
%Maybe move to prerpcessing
Data augmentation techniques are popular in studies with relatively limited
datasets. Techniques such as flipping, rotating, scaling and colour manipulation
not only enhance the size of the original dataset but also lower the likelihood
of the model overfitting \cite{DataAugmentationCanImproveRobustness},
\cite{AnOverviewOfOverfittingAndItsSolutions}. The paper by Shapiee et al.
\cite{skatePaper1} utilises three rotation augmentation techniques: horizontal
rotation, positive 90°rotation and negative 90°rotation. The researchers
experimented on three Transfer learning models: MobileNet, NASNetMobile and
NASNetLarge, each evaluated using a k-Nearest Neighbor (k-NN) classifier. As a
result, the models demonstrated impressive classification accuracies, with
MobileNet achieving 95\%, NASNetMobile 92\% and NASNetLarge 90\%. 

\paragraph{}
Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs) are
popular architectures due to their capabilities in modelling the dynamic
relationships in sequential data \cite{UnderstandingLSTM}. In the student
abstract by Hanciao Chen \cite{SkateboardAIPaper}, extensive experimentation is
conducted using diverse models, exploring various combinations of CNN-LSTM and
CNN-BiLSTM architectures. The study also incorporated attention mechanisms and
explored transfer-based methods for action recognition. 
%Add more information on 
This study further
documents and analyses important metrics such as training time, training
accuracy and validation accuracy for each model experimented on. Among these,
the top three models that stood out in terms of validation accuracy were the
ResNet50 with Attention and BiLSTM (84\%), ResNet50 with BiLSTM (81\%) and
ResNet50 with LSTM (80\%). Chen's study provides valuable insight into the
application of diverse models in activity recognition in skateboarding. 

\section{Model Evaluation and Challenges}

% Discuss the evaluation metrics used in these studies, like accuracy, precision, recall, etc.
% Address challenges like overfitting, especially in the context of studies reporting unusually high accuracies.

\section{Conclusion of the Literature Review}