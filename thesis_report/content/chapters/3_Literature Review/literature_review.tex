\clearpage
\chapter{Literature Review}


\section{Activity Recognition}
Building on the foundational understanding of activity recognition defined in
the background, it's important to acknowledge the impact it has on various
sectors. The recent advancements in recognising human actions in videos have
have not only revolutionalised sectors such as healthcare and security as
demonstrated in the studies \cite{3DhumanActionDetectionForHealthCareSystems},
\cite{HumanActivityRecognitionSecurityAndMonitoring}, but also hold extensive
potential in the realm of sports. 

The research conducted by K. Host and M. Ivašić-Kos in
\cite{HARinSportsComputerVision} along with Wu et al. in
\cite{Asurveyonvideoactionrecognitioninsports:Datasetsmethodsandapplications}
further elaborate on this potential, such as its numerous applications in
categorising complex sports actions, injury prevention methods and refinement of
game strategies through video analysis. These studies also propose various
methodological advancements, including the utilisation of Deep Learning models
to enhance accuracy, the exploration of multimodal data sources for sports
activities and an emphasis on real-time analysis capabilities. These insights
provide valuable techniques that can be leveraged for the development of
activity recognition models in the field of sports.

The study by Beddiar et al. \cite{VisionBasedHARASurvey}, identifies two main streams of
Human-computer interaction (HCI) technologies: Contact-based and
Vision-based systems. The authors categorise contact-based HCI as those
technologies that require physical user interaction through mediums such as
accelerometers, wearable sensors and multi-touch interfaces. 
% Complimenting this perspective, the study by Cook et al. \cite{SensorBasedActivityRecognition}
% delves into the specifics of sensor technology, exploring how various sensor
% types are significant in the field of activity recognition.
Alternatively, the authors describe vision-based methods as the simplification
of HCI due to more natural human communication, eliminating the need for
physical contact or equipment. These methods use image and video data to
recognise human activities offering an advantage in terms of societal acceptance
and usability.

While both contact and vision-based systems have their merits, this study will
specifically focus on vision-based techniques and their application in the
development of a skateboard trick classifier. These methods, which utilise image
and video data to recognise human activities are selected due to their
societal acceptability and their applicability in sports broadcasts.


\subsection{Challenges in this field}

The domain of Activity recognition comes with many challenges as depicted by
Zhang et al. (2017)
\cite{ReviewOfHumanActivityRecognitionUsingVisionBasedMethod}. The researchers
suggest that while certain scenarios utilise static cameras such as surveillance
systems, most situations that benefit from Activity Recognition adopt
dynamic recording devices such as mobile phones and sports event broadcasts.
These dynamic devices introduce a significant level of complexity as a result of
their tricky dynamic backgrounds present in video footage. Zhang et al. also
point out specific difficulties posed by long-distance and low-quality videos,
often encountered in environments like crowded public spaces and sports events.
The camera distance, results in smaller subjects, making detailed analysis of
human movements more challenging while lower-quality videos further complicate
the task for Human Activity Recognition (HAR) systems. 

The challenges highlighted by Zhang et al.
\cite{ReviewOfHumanActivityRecognitionUsingVisionBasedMethod} in the domain of
activity recognition are directly relevant to the development of a skateboard
trick classifier. In scenarios like televised skateboarding events, skaters may
appear relatively small to accommodate the entire skatepark, This factor along
with the complexity of the background as a result of dynamic recording poses a
challenge for trick recognition in live broadcasts. Furthermore, if a skateboard
trick classifier is intended for personal development, then it may encounter
videos of lower quality further complicating the task of trick recognition.
Addressing these challenges is crucial for the development of a skateboard trick
classifier that performs well in real-world conditions.

\subsection{Preprocessing techniques}
Preprocessing is a crucial step in the development of ML models, especially in
the field of activity recognition. It involves the application of various
techniques to enhance raw data before feeding it to Machine Learning algorithms. ---continue or leave out

As a result of the limited research on the emergence of a skateboard
trick classifier, there is a significant lack of open-source datasets featuring
skateboard tricks. This lack of data presents an opportunity to employ data
augmentation techniques, especially valuable in studies with limited data.
Methods such as flipping, rotating, scaling and colour manipulation not only
artificially enhance the size of the original dataset but also lower the
likelihood of overfitting as highlighted in prior works, \cite{DataAugmentationCanImproveRobustness},
\cite{AnOverviewOfOverfittingAndItsSolutions}. In the realm of Skateboard trick
classifiers, Shapiee et al (2020) \cite{skatePaper1} effectively employed data
augmentation techniques to expand their dataset, demonstrating the application
of these methods in improving model performance for trick classification.

After establishing the role of data augmentation in addressing the lack of data
available, another important step in computer vision is data normalisation. This
technique is essential for standardising the range and distribution of pixel
values in an image and has shown an increase in model performance,
\cite{RobustnessInMLNormalisation},
\cite{RealWorldMicroGraphDataQualityNORMALIZATIONCITE}. Min-max normalisation is
particularly prevalent in normalising pixel intensities to a 0-1 scale as
follows:

\begin{equation}
	\text{Normalized Value} = \frac{\text{Pixel Value} - \text{Min Value}}{\text{Max Value} - \text{Min Value}}
\end{equation}
While less common in computer vision due to its normality assumption,
Z-score normalisation is defined as:
\begin{equation}
	\centering
	\text{Z-score} = \frac{x - \mu}{\sigma}
\end{equation}
Here, $x$ represents the individual pixel value, $\mu$ is the mean of all pixel
values, and $\sigma$ is their standard deviation.

The research by Pei et al. (2023) \cite{RobustnessInMLNormalisation}, explored
the impact of normalisation on classification accuracy. They demonstrated that,
for 8-bit images, min-max normalisation outperformed Z-score, significantly
enhancing classification accuracy. On the other hand, the study by de Raad et
al. \cite{EffectOnPreProcessingOnCNNForMedicalImageSegmentation} suggests that
the impact of normalisation on model performance varies depending on certain
dataset characteristics. These contrasting conclusions presented by both studies
suggest that while normalisation is an important preprocessing step, its
application should be carefully adapted to the characteristics of the dataset.

Having optimised the distribution of pixel values through the normalisation
process, the next crucial step is feature extraction. Xudong Jiang
\cite{FeatureExtractionForImageRecognitionAndComputerVision}, describes this
technique as the process of capturing the core attributes of an object through
the elimination of redundancies, resulting in a set of numerical features ideal
for classification. CNNs excel at this due to their capabilities in detecting
complex patterns and enhancing features. While they are primarily used in image
recognition, as an initial step before deploying classification algorithms,
their effectiveness in feature extraction is demonstrated by studies like
Manjunath Jogin et al. (2018) \cite{FeatureExtractionUsingCNNandDeepLearning}
where they achieved 86\% accuracy using CNNs for feature extraction alongside
several classifiers. Beyond this primary function, CNN's ability to extract
complex features from images makes them very effective when coupled with other
models for more complex tasks such as activity recognition. In the context of
skateboard trick classification, CNNs can efficiently extract detailed spatial
features like board rotations, foot positioning and limb movements. Such
features can then be passed through a sequence analysis model like an LSTM,
proven to be efficient at understanding temporal information.

% This
% requires CNNs operating on individual frames to extract spatial features, which
% can then be passed through a sequence analysis model like an LSTM, proven to be
% efficient at understanding temporal information.


Following the discussion on CNNs for feature extraction, it is important to
highlight the role of transfer learning in enhancing ML models, especially in
fields with limited data like skateboard trick classification. The concept of
transfer learning as detailed by the studies \cite{ASurveyOfTransferLearning}
and \cite{ApplicationAndAnalysisOfTransferLearningSurvey} involves using a
pre-trained ML model to leverage its experience for a new, but related task. The
study by Sargano et al. (2017)
\cite{HARUsingTransferLearningWithDeepRepresentations}, employed transfer
learning with pre-trained deep CNNs like AlexNet \cite{AlexNetCite} and
GoogleNet \cite{GoogleNetCite}, for human activity recognition. Notably, they
utilised these models for feature extraction, followed by an SVM
classifier for final classification. Their approach showcases the
resource-efficient and time-saving nature of transfer learning, evident in their
impressive accuracies of 98.15\% and 91.47\%. Moreover, research on transfer
learning is not unique within the field of skateboard trick classification. Two
other studies \cite{skatePaper1}, \cite{SkateboardAIPaper} have utilised this
approach and achieved high accuracies, however, a more in-depth analysis of
these papers can be found in the 'Advancements in Skateboard Trick
Classification' section. These studies strongly suggest the exploration of
various pre-trained models for feature extraction in the development of a
skateboard trick classifier.


% Feature extraction techniques - using transfer learning, optical flow, object detection
%look into optical flow due to the dynamic notion of skateboard tricks - paper HARInSports
%look into Histogram of Oriented Gradient (HOG) 3D features,

\subsection{Activity Recognition Techniques}
The accurate classification of skateboard tricks poses a unique challenge for
computer vision due to the sport's dynamic and complex nature, characterised by
rapid movements, potential occlusions and camera angles. This section explores
various computer vision techniques and architectures employed in previous
literature, exploring their potential impact on this specific task. 

Deep learning (DL) techniques have become increasingly popular over traditional
ML methods, for their ability to learn feature representations automatically
from raw data, significantly improving performance
\cite{AReviewOnComputerVisionBasedMethodsForHARRecognition}. One particularly
effective DL architecture is the CNN-LSTM. This approach leverages the CNNs
strength in extracting spatial features from individual frames and LSTMs ability
to capture temporal information across frames, leading to a deeper understanding
of video content.

The study by Orozco et al. (2020)
\cite{HARRecognitionInVideosUsingARobustCNNLSTMApproach} adopted this approach
to test its effectiveness against three activity recognition datasets: KTH,
UCF-11, HMDB-51, particularly focusing on how the number of LSTM units impacted
performance. The authors employed transfer learning, utilising the VGG16 model
\cite{VGG} for feature extraction from videos, followed by an LSTM network for
classification. Their findings show that 360 LSTM units achieved an accuracy of
93.86\% on the KTH dataset, while 320 units led to an accuracy of 91.93\%.
However, the performance on the HMDB-51 dataset dropped, with 400 LSTM units
resulting in a lower accuracy of 47.36\%. These findings show the potential of
the CNN-LSTM approach, particularly for simpler datasets, highlighting the need
for further investigation and optimisation for more complex datasets like
HMDB-51.
\clearpage
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.65 \textwidth]{content/chapters/3_Literature Review/figures/cnn-lstm.png} 
	\caption{CNN-LSTM Architecture. Reproduced from Donahue et al. (2015) \cite{LongTermRecurrentConvolutionalNetworksForVisualRecognitionAndDescription}}
	\label{fig:CNN-LSTM-architecture} 
  \end{figure}
  

Building upon the foundational CNN-LSTM architecture, a recent study by Saoudi
et al. (2023)
\cite{Advancinghumanactionrecognition:ahybridapproachusingattention-basedLSTMand3DCNN}
enhances this model by incorporating three key advancements:

\begin{description}
	\item[1. 3D Convolutional Neural Networks (3D CNNs):] Unlike regular CNNs,
	data is processed as 3D volumes, enabling them to capture both
	spatial and temporal information by performing convolution operations on all
	three dimensions: width, height and time. The authors opted to use the I3D
	model, leveraging transfer learning to bypass the resources
	required to train one from scratch. The I3D model was selected for its
	proven efficiency and its ability to be fine-tuned for activity recognition
	tasks.  
	\item[2. Bi-directional Long-Short-Term Memory (BiLSTM) network:] The
	authors chose to use a variant of LSTM called Bi-directional Long Short-Term
	Memory (BiLSTM). Whereas LSTMs only process data in one direction, BiLSTMs
	can analyse data in both directions, allowing them to understand
	relationships between preceding and subsequent actions.
	\item[3. Attention Mechanisms:]  Saoudi et al. incorporated attention
	mechanisms after their BiLSTM, enabling the model to prioritise particular
	parts of the input data. This technique allowed the model to learn which
	temporal features were most applicable to the task, providing a more detailed
	representation of the input and ultimately, improved performance.
\end{description}

With the integration of these advancements, Saoudi et al. achieved model
accuracies of 97.98\% and 96.83\% on the HMDB51 and UFC101 datasets
respectively, demonstrating the potential of 3D CNNs, BiLSTMSs and attention mechanisms
for activity recognition tasks.

%Notably the CNN-LSTM architecture is an effective model in accurately recognising human activities, this is outlined in the study by Ronald Mutegeki \cite{CNN-LSTMApproachToHAR}. The author reports this architecture achieving 99\% and 92\% on the iSPL and UCI HAR datasets respectively, showcasing the strength of CNN's for extracting spatial features from data, especially in the field of activity recognition.

%CNN-LSTM is a popular approach in HAR use cite \cite{HumanActivityRecognitionSystem:StateOfTheArt}

%% to mention: CNN-LSTM, Attention, BILSTM

%Maybe first mention that ML classification can be used, but more recently, deep
%learning has been favourable HARinSports K. host, then move on to different
%studies and how they tackled activity recognition by discussing the evolution
%from machine learning to deep learning in activity recognition, and why deep
%learning might be more effective for your study

% align with the insights from the
% paper by K. Host and M. Ivašić-Kos \cite{HARinSportsComputerVision}. This paper
%While Contact based is good, this study will focusing on computer vision

\section{Advancements in Skateboard Trick Classification}

In the emergent field of skateboard trick classification, leveraging activity
recognition techniques from a video have led to two primary methodologies among
researchers. The first technique involves utilising signals obtained from
skateboard-mounted accelerometers or signals artificially generated based on the % maybe change the wording
findings of prior studies. These signals are then fed into a study-dependent
model for classification, as outlined by Abdullah et al. (2021)
\cite{skateboardClassificationTransferLearningPipelinesAccelermetry} and Corrêa
et al. (2017) \cite{skateboardTrickClassifierUsingAccelerometryAndML}. The
second approach employs computer vision techniques, leveraging video footage of
skateboard tricks to train and refine models for accurate trick identification,
as depicted by the studies Shapiee et al. (2020) \cite{skatePaper1} and  Hanciao
Chen (2023) \cite{SkateboardAIPaper}. 

\subsection{Accelerometer-based approaches}

The study by Abdullah et al. (2021)
\cite{skateboardClassificationTransferLearningPipelinesAccelermetry}, makes use
of a custom dataset comprising six skateboard tricks most commonly executed
in competitive events. Amateur skateboarders performed each trick five times on
a modified skateboard equipped with an Inertial Measurement Unit (IMU) to record
the signals produced. The researchers capture six signals for each trick,
including linear accelerations along the x, y, and z axes (aX, aY, aZ) and
angular accelerations along the same axes (gX, gY, gZ). They then opt for the
unique approach of concatenating all six signals onto a single image
corresponding to one trick, employing two input image transformations: raw data
(RAW) and Continuous Wavelet Transform (CWT). 

With the application of six transfer learning models on this data, Abdullah et
al. \cite{skateboardClassificationTransferLearningPipelinesAccelermetry} reports
exceptionally high accuracies, achieving a 100\% test accuracy over multiple
models. While these results are remarkable, very high levels of accuracy are
rare in ML applications and are typically associated with models that may be
overfitting the data. Recognising the rarity of such high accuracies, this study
will consider these findings and efforts will be made to ensure a
robust model by employing techniques to avoid overfitting such as early-stopping
and the use of a diverse dataset \cite{AnOverviewOfOverfittingAndItsSolutions}.
% the results show that RAW and CWT input
% images on MobileNet, MobileNetV2 and ResNet101 models achieved favourable
% accuracy. However, the CWT-MobileNet-Optimised SVM pipeline was deemed the best
% due to its reduction in computational time.


The study by Corrêa et al. (2017)
\cite{skateboardTrickClassifierUsingAccelerometryAndML}, obtained their sample
data by artificially generating 543 signals based on prior research, utilising
tools such as MATLAB 2015 and Signal Processing Toolbox. These signals were then
categorised into five distinct classes representing different skateboard tricks,
each with various samples ranging from 30 to 50 per class, across three axes (X,
Y and Z). This study developed and validated individual Artificial Neural
Networks (ANNs) for each axis, as well as the combination of the three: ANN XYZ,
displaying the potential of Neural Networks to categorise multidimensional
skateboard tricks. The ANNs are all multilayer feed-forward neural networks
(MFFNNs), structured into three distinct layers. They feature an input layer
with 82 neurons, a hidden layer, comprised of 23 neurons utilising a tan-sigmoid
transfer function and an output layer consisting of 5 neurons with a softmax
function. Finally, the study achieved high accuracies, with ANNs X, Y and Z
achieving 94.8\%, 96.7\% and 98.7\%, respectively, while the
combined ANN XYZ achieved an accuracy of 92.8\%. 


\subsection{Computer Vision-based Approaches}

The paper by Shapiee et al. (2020) \cite{skatePaper1} leverages a custom data set
comprising videos capturing the execution of five distinct skateboard tricks,
each attempted five times. Each video spans two to three seconds, yielding a
total of 750 images by extracting 30 frames per video. This study made use of
data augmentation techniques to expand their dataset further. Consequently, they
introduced an additional 2,250 images, achieving 3,000 images in their data set.
On the other hand, Chen (2023) \cite{SkateboardAIPaper} compiled a comprehensive
data set by collecting videos from multiple platforms, including YouTube,
Twitter and Instagram. Furthermore, Chen trained the model using 15 fundamental
tricks commonly observed in competitive settings. The researcher collected 50
videos per trick, summing up to a total number of 750 videos. Of these, 45
videos per trick were allocated for training, and the remaining 5 were reserved
for validation. 


%Maybe move to preprocessing
% Data augmentation techniques are popular in studies with relatively limited
% datasets. Techniques such as flipping, rotating, scaling and colour manipulation
% not only enhance the size of the original dataset but also lower the likelihood
% of the model overfitting \cite{DataAugmentationCanImproveRobustness},
% \cite{AnOverviewOfOverfittingAndItsSolutions}. 
%Mention more here !!!!
The paper by Shapiee et al. \cite{skatePaper1} utilises data augmentation
techniques with the application of three rotations to the images: horizontal rotation,
positive 90°rotation and negative 90°rotation. The researchers experimented on
three Transfer learning models: MobileNet, NASNetMobile and NASNetLarge, each
evaluated using a k-Nearest Neighbor (k-NN) classifier. As a result, the models
demonstrated impressive classification accuracies, with MobileNet achieving
95\%, NASNetMobile 92\% and NASNetLarge 90\%. 


%Recurrent Neural Networks (RNNs) and Long Short-Term Memory Networks (LSTMs) are
%popular architectures due to their capabilities in modelling the dynamic
%relationships in sequential data \cite{UnderstandingLSTM}. 
In the student abstract by Hanciao Chen \cite{SkateboardAIPaper}, extensive experimentation is
conducted using diverse models, exploring various combinations of CNN-LSTM and
CNN-BiLSTM architectures. The study also incorporated attention mechanisms and
explored transfer-based methods for activity recognition. 
%Add more information on 
This study further documents and analyses important metrics such as training time, training
accuracy and validation accuracy for each model experimented on. Among these,
the top three models that stood out in terms of validation accuracy were the
ResNet50 with Attention and BiLSTM (84\%), ResNet50 with BiLSTM (81\%) and
ResNet50 with LSTM (80\%). Chen's study provides valuable insight into the
application of diverse models in activity recognition in skateboarding. 

%\section{Model Evaluation and Challenges}

% Discuss the evaluation metrics used in these studies, like accuracy, precision, recall, etc.
% Address challenges like overfitting, especially in the context of studies reporting unusually high accuracies.













