\clearpage
\chapter{Background}

\section{Skateboard Tricks}

% Performing a skateboard trick requres an intricate motion between the body and
% the board, demanding precise coordination and athleticism. 

Skateboard tricks can be described as dynamic manoeuvres that involve complex coordination of the skateboard and the skateboarder's body. Skateboard tricks can be categorised into several types, including rotations, grinds, performed on ledges or rails and manuals, where the skater balances on two wheels. The key to successfully performing these tricks is appropriate foot placement, which is critical for controlling the skateboard’s speed and direction. This control allows skateboarders to manipulate the board in ways that replicate specific tricks, showcasing not only their technical abilities and creativity.
 
%  thorugh complex motions of the body and , to initiate various
%  rotations and revolutions along various axes. 

% Skateboard tricks are the heart and soul of skateboarding. These tricks
% originate from the dynamic orchestration of rotations and revolutions of a
% skateboard along various axes emphasising the significance of precise placement
% of a skateboarder's feet to initiate these rotations. These tricks serve as
% excellent examples of how the skateboarder's body and skateboard work in perfect
% harmony. Some common skateboard tricks include:

\begin{itemize}
    \item \textbf{Ollie:} One of the first tricks beginners learn. Where the
    skateboarder pops the tail of the board while simultaneously sliding their foot across the nose of the
    board, causing the board to level out in the air, used to jump over
    obstacles.
    \item \textbf{Kickflip:} A trick where the skateboarder flips the board
    under their feet while jumping, making it spin 360\textdegree around the
    x-axis.
    \item \textbf{Pop-Shuvit:} A trick where the skateboarder scoops the board
    with their back foot causing a 180\textdegree rotation around the y-axis.
\end{itemize}

Skateboarders continually innovate and come up with new trick combinations,
contributing to the dynamic nature of the sport.



\section{Machine Learning}

Machine Learning (ML) can be defined as a field of study that explores
algorithms and statistical models employed by computer systems to execute tasks
without the need to be explicitly programmed. It is particularly applicable in
situations where the information we seek from a dataset is not interpretable,
and as the volume of available datasets continues to surge so does the demand
for machine learning \cite{ML_Algorithms}.

Morris (2019) \cite{UnderstandingLSTM} characterises ML as the advancement of
algorithms that progressively enhance their performance through practice,
suggesting that the more training the learning algorithm undergoes, the better
it becomes at executing tasks. Numerous critical factors shape a
model's performance within this phase, as exemplified by Budach et al. (2022)
\cite{TheEffectsofDataQualityonMachineLearningPerformance}. Such factors
include dataset quality and diversity, data preprocessing, the selection
of a suitable model architecture, training time and the
fine-tuning of hyper-parameters.

There exist three main categories for ML models \cite{ML_Algorithms}:
\begin{itemize}
    \item \textbf{Supervised:} This is a ML concept that involves training a model to make classifications based on input data that has been labelled with the correct label.
    \item \textbf{Unsupervised:} This ML concept concentrates on discovering
    relationships within data when there are no predefined "correct" answers or
    labelled examples to guide the learning process. These models are left
    to autonomously explore and divulge structures in the data.
    \item \textbf{Reinforcement:} This type of learning consists of an agent
    that interacts with the environment and learns from the continuous feedback
    it receives in the form of rewards or punishment.
\end{itemize}

%\section{Object Detection}

%Object detection is a computer vision task that detects instances of objects in images and videos and maps them to a predefined class. For humans, the act of recognising and responding to objects is a trivial task as described by Watson et al. (2016) \cite{NeuralScience}, it is an essential feature that enables our performance and communication. Numerous researchers have shown a deep interest in this technology, focusing on various applications where object detection may play a major role, such as  surveillance systems, face detection and autonomous driving \cite{RecentAdvancesObjectDetection}. 

%The output of an object detection model returns the location of the instance, as the object's centre or in the form of a bounding box. The research paper by Agarwal et al. (2018) \cite{RecentAdvancesObjectDetection} defines object
%detection as the following equation where an image is denoted as \(\mathcal{I}\), and \(O(I)\) represents the collection of object descriptions for objects within the image.
%that object detection is consistently defined within the context of a data set
%that consists of images mapped to a list of relevant object properties, such as

%their locations and scales, that are specified within each image. This
%definition makes references to the equation below,
%\begin{equation}
%O(I) = \{(Y^*_1, Z^*_1), \ldots, (Y^*_i, Z^*_i), \ldots, (Y^*_{N^*i},
%Z^*_{N^*i})\}
%\end{equation}


%In the above equation, each description encompasses two parts, \(Y^*_i \in\mathcal{Y}\) characterises the category or type of an object, and \(Z^*_{N^*i}\in \mathcal{Z}\) represents information about its location, size or shapewithin the image. \(\mathcal{Z}\) represents the different ways to describe anobject, this is typically done by specifying the object's centre \((x_c, y_c)\in \mathcal{R}^2\) or as a bounding box \((x_{min}, y_{min},x_{max},y_{max})\in \mathcal{R}^4\). 
%By utilising these notations, according to
%\cite{RecentAdvancesObjectDetection}, object detection can be defined as the
%operation of combining an image with a set of detections. 
%In this research
%paper, images are passed through an object detection model as one of the
%pre-processing steps before passing through the main AI model. This strategy is
%employed with the primary objective of utilising the bounding box output to
%facilitate the cropping of individual skateboarder frames, thus contributing to
%a notable reduction in computational overhead.


\section{Activity Recognition}

 Activity recognition is the process of identifying and categorizing human
 activities from video sequences. Human activities involve a wide range of
 motions and interactions with objects, varying from simple isolated actions
 like dancing to more complex activities that engage multiple body parts and
 external objects such as a football match. The human ability to perceive these
 behaviours is a trivial task; yet, it is a challenging problem for computers
 due to the sequential nature and the resemblance of visual content in such
 activities \cite{ActionRecognitionDeepBi-DirectionalLSTM,
 AReviewOfHumanActivityRecognitionMethods}.

% This should probably go to the implementation section
 %  Recognising complex human actions demands the examination of sequential data as
%  opposed to relying on single frames or images
%  \cite{ActionRecognitionDeepBi-DirectionalLSTM}. To illustrate this point,
%  consider the example of a skateboarder executing a challenging trick like the
%  "Kickflip", as depicted in Figure \ref{fig:SingleVsMultiFrameKickflip}. If we
%  were to feed a single frame of this trick into an AI model, as shown in Figure
%  \ref{fig:singleFrameKickflip}, it may misinterpret the manoeuvre as another
%  trick. Whereas, by providing the model with a sequence of frames, as shown in
%  Figure \ref{fig:MultiFrameKickflip}, it captures the entire essence of the
%  trick portraying the dynamic progression of actions such as foot placement,
%  board rotation and landing which collectively define the skateboard trick.

%  %Skater frame images
% \begin{figure}[h]
%   \begin{subfigure}{0.5\textwidth}
%     \centering
%     \includegraphics[width=0.57\linewidth]{content/chapters/2_background/figures/Tricks/single.png}
%     \caption{A Single Frame of a "Kickflip".}
%     \label{fig:singleFrameKickflip}
%   \end{subfigure}
%   \begin{subfigure}{0.5\textwidth}
%     \centering
%     \includegraphics[width=1\linewidth]{content/chapters/2_background/figures/Tricks/KickflipFrames.PNG}
%     \caption{Multiple Frames of a "Kickflip".}
%     \label{fig:MultiFrameKickflip}
%   \end{subfigure}
%   \caption{Comparison of a Single Frame and Multiple Sequential Frames.}
%   \label{fig:SingleVsMultiFrameKickflip}
% \end{figure}



\section{Neural Networks}
\subsection{Artificial Neural Networks}

Artificial Neural Networks (ANNs) are a class of machine learning models that
are inspired by the interconnected systems of neurons found in the nervous
system of living organisms. They consist of connected nodes capable of learning
from their environment and adapting to complex patterns in data
\cite{FundamentalsOfNeuralNetworks}. Figure \ref{fig:ANN_Diagram} depicts a
schematic representation of an ANN. The diagram is organised into three
fundamental layers: the Input Layer, the Hidden Layer(s) and the Output Layer
\cite{FundamentalsOfArtificialNeuralNetworksAndDeepLearning}.  

\begin{itemize}
    \item \textbf{Input Layer:} This is the set of neurons that serve as the
    initial entry point for external data. Each input neuron in this
    layer corresponds to a specific feature or variable used in the Neural
    Network model.  
    \item \textbf{Hidden Layer(s):} This is the set of neurons that are located
    between the Input and Output Layers where the network captures complete
    non-linear behaviours of data and feature transformations.
    \item \textbf{Output Layer:} This is the set of neurons that provide the
    final predictions produced by the neural network. Depending on how the ANN
    is configured, the final output can be continuous, binary, ordinal, or
    count.
\end{itemize}

\begin{figure}[ht]
	\centering
  \includegraphics[width=0.75 \textwidth]{content/chapters/2_background/figures/Machine Learning/ANN_Diagram2.png} 
  \caption{Schematic Representation of an Artificial Neural Network. Reproduced from López et al. (2022) \cite{FundamentalsOfArtificialNeuralNetworksAndDeepLearning}}
  \label{fig:ANN_Diagram} 
\end{figure}

\subsection{Convolutional Neural Networks}
Convolutional Neural Networks (CNNs), as described by Gu et al. (2018)
\cite{RecentAadvancesInConvolutionalNeuralNetworks} are a category of Deep
learning architectures with roots in the biological visual perception mechanisms
of living organisms. These networks have gained widespread attention for their
incredible performance in various fields such as visual recognition, speech
recognition and natural language processing.

CNNs, incorporate multiple layers and are capable of extracting effective
representations

-- continue explanation, explain how feature maps are created through convolutions

\subsection{Recurrent Neural Networks}
Recurrent Neural Networks (RNNs) are a subset of Neural networks that are
designed for sequential data processing. RNNs are capable of modelling
dynamic relationships in sequential data by feeding signals from past time steps
back into the network. However, they are limited by their
inability to access long-term data, limited to approximately ten sequential time
steps. This constraint arises from the challenge of dealing with vanishing or
exploding gradients in the backpropagation procedure while processing
extended sequences, as discussed in prior works
\cite{UnderstandingLSTM},\cite{Long-termConvolutionalNeuralNetworksforVisualRecogntion}. 
\subsubsection{Long Short-Term Memory Networks}
To address the limitation that RNNs encounter in capturing long-term
dependencies, Long Short-Term Memory Recurrent Neural Networks (LSTM-RNNs) were
introduced as an extention to RNNs in 1997
\cite{learningPriceseTimingWithLSTM,originalLSTMPaper}. LSTM networks inherently
extend the RNNs memory enabling them to campture dependencies across more than
1,000 time steps depending on the network's complexity. These models are also
able to tackle the vanishing problem associated with RNNS and offer more
biologically credible solution \cite{UnderstandingLSTM}. 

These types of networks consist of three gates: input, output and forget gates.
The input gate, determines whether new information will be uploaded to the
network, the output gate manages whether current cell values contribute to the
output, and the forget gate determines whether existing information will be
preserved or removed \cite{theperformanceoflstmandbilstminforcastingtimeseries}.
Figure \ref{fig:lstm_architecture} illustrates the architecture of an LSTM
network, displaying the interaction between the cell state and the various other
gates that regulate the flow of information through the network.


\begin{figure}[ht]
	\centering
  \includegraphics[width=0.9 \textwidth]{content/chapters/2_background/figures/lstm_architecture.jpg} 
  \caption{LSTM architecture. Reproduced from ...........}
  \label{fig:lstm_architecture}
\end{figure} %https://d2l.ai/chapter_recurrent-modern/lstm.html reproduced from


\subsubsection{Bidirectional LSTMs}
Bidirectional LSTMs (BiLSTMs) are sophisticated variants of LSTMs designed to
ehnance the ability to capture patterns in time series data and improve learning
long-term dependencies. Unlike LSTMs that only process data in a single
direction (from past to future), BiLSTMs utilise a more intuitive approach by
applying two LSTM models to the input data.  In the first round, the LSTM is
applied to the input data, and in the second round, it is applied to the
reversed input sequence. Furthermore, Tavakoli et al. (2019)
\cite{theperformanceoflstmandbilstminforcastingtimeseries}, concluded that
BiLSTMs reported better accuracies compared to regular LSTMs.
%%Describe BiLSTM TODO


\begin{figure}[ht]
	\centering
  \includegraphics[width=0.9 \textwidth]{content/chapters/2_background/figures/bilstm_structure.png} 
  \caption{BiLSTM Structure. Reproduced from Du et al. (2020) \cite{du2020power}} 
  \label{fig:bilstm_structure}
\end{figure} %https://d2l.ai/chapter_recurrent-modern/lstm.html reproduced from

Figure \ref{fig:bilstm_structure} 

%This diagram represents the structure of a bidirectional LSTM (BiLSTM) network,
%which is designed to process sequences of data by considering both past
%(forward) and future (backward) context at each time step. In the depicted
%structure, you can see two layers that run in parallel: the top layer processes
%the sequence from the beginning to the end (forward direction), while the
%bottom layer processes the sequence in the reverse order (backward direction).

%Each circle in the diagram denotes a hidden state at a particular time step. The
% hidden states in the forward layer are connected through weights Wf1Wf1​ and
% Wf2Wf2​, while the hidden states in the backward layer are connected through
% weights Wb1Wb1​ and Wb2Wb2​. The dashed arrows represent these connections,
% indicating how information is passed from one state to the next within each
% respective layer.

% The inputs to the network are represented by x1,x2,...,x6x1,x2,...,x6, and these
% are fed into both the forward and the backward layers of the network. For each
% time step, the network generates an output, represented by
% y1,y2,...,y6y1,y2,...,y6, which is influenced by the information from both the
% past and the future context as learned by the network.

% The unique aspect of this architecture is its ability to preserve information
% from both ends of the sequence, allowing for more complex patterns to be
% recognized that a unidirectional LSTM might not capture. This is particularly
% useful in tasks like time series forecasting, natural language processing, and
% other sequence-based problems where the context from both directions can be
% highly informative for making predictions or understanding the sequence as a
% whole.

