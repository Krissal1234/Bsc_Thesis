\clearpage
\chapter{Background}

\section{Skateboard Tricks}

% Performing a skateboard trick requres an intricate motion between the body and
% the board, demanding precise coordination and athleticism. 

Skateboard tricks can be described as dynamic manoeuvres that involve complex coordination of the skateboard and the skateboarder's body. Skateboard tricks can be categorised into several types, including rotations, grinds, performed on ledges or rails and manuals, where the skater balances on two wheels. The key to successfully performing these tricks is appropriate foot placement, which is critical for controlling the skateboard’s speed and direction. This control allows skateboarders to manipulate the board in ways that replicate specific tricks, showcasing not only their technical abilities and creativity.
 
%  thorugh complex motions of the body and , to initiate various
%  rotations and revolutions along various axes. 

% Skateboard tricks are the heart and soul of skateboarding. These tricks
% originate from the dynamic orchestration of rotations and revolutions of a
% skateboard along various axes emphasising the significance of precise placement
% of a skateboarder's feet to initiate these rotations. These tricks serve as
% excellent examples of how the skateboarder's body and skateboard work in perfect
% harmony. Some common skateboard tricks include:

\begin{itemize}
    \item \textbf{Ollie:} One of the first tricks beginners learn. Where the
    skateboarder pops the tail of the board while simultaneously sliding their foot across the nose of the
    board, causing the board to level out in the air, used to jump over
    obstacles.
    \item \textbf{Kickflip:} A trick where the skateboarder flips the board
    under their feet while jumping, making it spin 360\textdegree around the
    x-axis.
    \item \textbf{Pop-Shuvit:} A trick where the skateboarder scoops the board
    with their back foot causing a 180\textdegree rotation around the y-axis.
\end{itemize}

Skateboarders continually innovate and come up with new trick combinations,
contributing to the dynamic nature of the sport.



\section{Machine Learning}

Machine Learning (ML) can be defined as a field of study that explores
algorithms and statistical models employed by computer systems to execute tasks
without the need to be explicitly programmed. It is particularly applicable in
situations where the information we seek from a dataset is not interpretable,
and as the volume of available datasets continues to surge so does the demand
for machine learning \cite{ML_Algorithms}.

Morris (2019) \cite{UnderstandingLSTM} characterises ML as the advancement of
algorithms that progressively enhance their performance through practice,
suggesting that the more training the learning algorithm undergoes, the better
it becomes at executing tasks. Numerous critical factors shape a
model's performance within this phase, as exemplified by Budach et al. (2022)
\cite{TheEffectsofDataQualityonMachineLearningPerformance}. Such factors
include dataset quality and diversity, data preprocessing, the selection
of a suitable model architecture, training time and the
fine-tuning of hyper-parameters.

There exist three main categories for ML models \cite{ML_Algorithms}:
\begin{itemize}
    \item \textbf{Supervised:} This is a ML concept that involves training a model to make classifications based on input data that has been labelled with the correct label.
    \item \textbf{Unsupervised:} This ML concept concentrates on discovering
    relationships within data when there are no predefined "correct" answers or
    labelled examples to guide the learning process. These models are left
    to autonomously explore and divulge structures in the data.
    \item \textbf{Reinforcement:} This type of learning consists of an agent
    that interacts with the environment and learns from the continuous feedback
    it receives in the form of rewards or punishment.
\end{itemize}

%\section{Object Detection}

%Object detection is a computer vision task that detects instances of objects in images and videos and maps them to a predefined class. For humans, the act of recognising and responding to objects is a trivial task as described by Watson et al. (2016) \cite{NeuralScience}, it is an essential feature that enables our performance and communication. Numerous researchers have shown a deep interest in this technology, focusing on various applications where object detection may play a major role, such as  surveillance systems, face detection and autonomous driving \cite{RecentAdvancesObjectDetection}. 

%The output of an object detection model returns the location of the instance, as the object's centre or in the form of a bounding box. The research paper by Agarwal et al. (2018) \cite{RecentAdvancesObjectDetection} defines object
%detection as the following equation where an image is denoted as \(\mathcal{I}\), and \(O(I)\) represents the collection of object descriptions for objects within the image.
%that object detection is consistently defined within the context of a data set
%that consists of images mapped to a list of relevant object properties, such as

%their locations and scales, that are specified within each image. This
%definition makes references to the equation below,
%\begin{equation}
%O(I) = \{(Y^*_1, Z^*_1), \ldots, (Y^*_i, Z^*_i), \ldots, (Y^*_{N^*i},
%Z^*_{N^*i})\}
%\end{equation}


%In the above equation, each description encompasses two parts, \(Y^*_i \in\mathcal{Y}\) characterises the category or type of an object, and \(Z^*_{N^*i}\in \mathcal{Z}\) represents information about its location, size or shapewithin the image. \(\mathcal{Z}\) represents the different ways to describe anobject, this is typically done by specifying the object's centre \((x_c, y_c)\in \mathcal{R}^2\) or as a bounding box \((x_{min}, y_{min},x_{max},y_{max})\in \mathcal{R}^4\). 
%By utilising these notations, according to
%\cite{RecentAdvancesObjectDetection}, object detection can be defined as the
%operation of combining an image with a set of detections. 
%In this research
%paper, images are passed through an object detection model as one of the
%pre-processing steps before passing through the main AI model. This strategy is
%employed with the primary objective of utilising the bounding box output to
%facilitate the cropping of individual skateboarder frames, thus contributing to
%a notable reduction in computational overhead.


\section{Activity Recognition}

 Activity recognition is the process of identifying and categorizing human
 activities from video sequences. Human activities involve a wide range of
 motions and interactions with objects, varying from simple isolated actions
 like dancing to more complex activities that engage multiple body parts and
 external objects such as a football match. The human ability to perceive these
 behaviours is a trivial task; yet, it is a challenging problem for computers
 due to the sequential nature and the resemblance of visual content in such
 activities \cite{ActionRecognitionDeepBi-DirectionalLSTM,
 AReviewOfHumanActivityRecognitionMethods}.

% This should probably go to the implementation section
 %  Recognising complex human actions demands the examination of sequential data as
%  opposed to relying on single frames or images
%  \cite{ActionRecognitionDeepBi-DirectionalLSTM}. To illustrate this point,
%  consider the example of a skateboarder executing a challenging trick like the
%  "Kickflip", as depicted in Figure \ref{fig:SingleVsMultiFrameKickflip}. If we
%  were to feed a single frame of this trick into an AI model, as shown in Figure
%  \ref{fig:singleFrameKickflip}, it may misinterpret the manoeuvre as another
%  trick. Whereas, by providing the model with a sequence of frames, as shown in
%  Figure \ref{fig:MultiFrameKickflip}, it captures the entire essence of the
%  trick portraying the dynamic progression of actions such as foot placement,
%  board rotation and landing which collectively define the skateboard trick.

%  %Skater frame images
% \begin{figure}[h]
%   \begin{subfigure}{0.5\textwidth}
%     \centering
%     \includegraphics[width=0.57\linewidth]{content/chapters/2_background/figures/Tricks/single.png}
%     \caption{A Single Frame of a "Kickflip".}
%     \label{fig:singleFrameKickflip}
%   \end{subfigure}
%   \begin{subfigure}{0.5\textwidth}
%     \centering
%     \includegraphics[width=1\linewidth]{content/chapters/2_background/figures/Tricks/KickflipFrames.PNG}
%     \caption{Multiple Frames of a "Kickflip".}
%     \label{fig:MultiFrameKickflip}
%   \end{subfigure}
%   \caption{Comparison of a Single Frame and Multiple Sequential Frames.}
%   \label{fig:SingleVsMultiFrameKickflip}
% \end{figure}



\section{Neural Networks}
\subsection{Artificial Neural Networks}

Artificial Neural Networks (ANNs) are a class of Machine Learning models that
are inspired by the interconnected systems of neurons found in the nervous
system of living organisms. They consist of connected nodes capable of learning
from their environment and adapting to complex patterns in data
\cite{FundamentalsOfNeuralNetworks}. Figure \ref{fig:ANN_Diagram} depicts a
schematic representation of an ANN. The diagram is organised into three
fundamental layers: the Input Layer, the Hidden Layer(s) and the Output Layer
\cite{FundamentalsOfArtificialNeuralNetworksAndDeepLearning}.  

\begin{itemize}
    \item \textbf{Input Layer:} This is the set of neurons that serve as the
    initial entry point for external data. Each input neuron in this
    layer corresponds to a specific feature or variable used in the Neural
    Network model.  
    \item \textbf{Hidden Layer(s):} This is the set of neurons that are located
    between the Input and Output Layers where the network captures complete
    non-linear behaviours of data and feature transformations.
    \item \textbf{Output Layer:} This is the set of neurons that provide the
    final predictions produced by the Neural Network. Depending on how the ANN
    is configured, the final output can be continuous, binary, ordinal, or
    count.
\end{itemize}

\begin{figure}[ht]
	\centering
  \includegraphics[width=0.75 \textwidth]{content/chapters/2_background/figures/Machine Learning/ANN_Diagram2.png} 
  \caption{Schematic Representation of an Artificial Neural Network. Reproduced from López et al. (2022) \cite{FundamentalsOfArtificialNeuralNetworksAndDeepLearning}}
  \label{fig:ANN_Diagram} 
\end{figure}

\subsection{Convolutional Neural Networks}
Convolutional Neural Networks (CNNs), as described by Gu et al. (2018)
\cite{RecentAadvancesInConvolutionalNeuralNetworks} are a category of Deep
learning architectures with roots in the biological visual perception mechanisms
of living organisms. These networks have gained widespread attention for their
incredible performance in the field of image recognition and pattern recognition tasks. 

% Unlike ANNs, CNNs have neurons arranged in three dimensions: width, height and
% depth.

CNNs are comprised of three types of layers: convolutional layers, pooling
layers and fully-connected layers. The convolutional layer applies a set of
filters (or kernels) that slide across the input data performing a localised dot
product between their weights and the corresponding values of the input data.
The results are summed up to generate a single value in the feature map. The
pooling layer applies an aggregation funciton such as max pooling or average
pooling to create a downsamplaed representation of the input data are. Finally,
the fully-connected attempt to transform the outputs from the previous layer
into an output vector that represents a score corresponding to a class label. 

\begin{figure}[h]
	\centering
  \includegraphics[width=0.7 \textwidth]{content/chapters/2_background/figures/cnn_arch.png} 
  \caption{CNN architecture comprising 5 layers. Reproduced from O'Shea and Nash (2015) \cite{introductiontoCNNs}}
  \label{fig:cnn_architecture}
\end{figure}

Figure \ref{fig:cnn_architecture} showcases a simplified CNN
architecture comprising of 5 layers, Nonethelss, the complexity of CNNs can be
scaled by stacking multiple layers, thereby increasing the network's depth to
cater for more complex tasks.


\subsection{Recurrent Neural Networks}
Recurrent Neural Networks (RNNs) are a subset of Neural networks that are
designed for sequential data processing. RNNs are capable of modelling
dynamic relationships in sequential data by feeding signals from past time steps
back into the network. However, they are limited due to their
inability to access long-term data, limited to approximately ten sequential time
steps.%add reference
This constraint arises from the challenge of dealing with vanishing or
exploding gradients in the backpropagation procedure while processing
extended sequences, as discussed in prior works
\cite{UnderstandingLSTM,Long-termConvolutionalNeuralNetworksforVisualRecogntion}. 
\subsubsection{Long Short-Term Memory Networks}
To address the limitation that RNNs encounter in capturing long-term
dependencies, Long Short-Term Memory Recurrent Neural Networks (LSTM-RNNs) were
introduced as an extention to RNNs in 1997
\cite{learningPriceseTimingWithLSTM,originalLSTMPaper}. LSTM networks inherently
extend the RNNs memory enabling them to campture dependencies across more than
1,000 time steps depending on the network's complexity. These models are also
able to tackle the vanishing problem associated with RNNS and offer more
biologically credible solution \cite{UnderstandingLSTM}. 

These types of networks consist of three gates: input, output and forget gates.
The input gate, determines whether new information will be uploaded to the
network, the output gate manages whether current cell values contribute to the
output, and the forget gate determines whether existing information will be
preserved or removed \cite{theperformanceoflstmandbilstminforcastingtimeseries}.
Figure \ref{fig:lstm_architecture} illustrates the architecture of an LSTM
network, displaying the interaction between the cell state and the various other
gates that regulate the flow of information through the network.

% explain how they solve the vanishing gradient problem
\begin{figure}[ht]
	\centering
  \includegraphics[width=0.9 \textwidth]{content/chapters/2_background/figures/lstm_architecture.jpg} 
  \caption{LSTM architecture. Reproduced from ...........}
  \label{fig:lstm_architecture}
\end{figure} %https://d2l.ai/chapter_recurrent-modern/lstm.html reproduced from


\subsubsection{Bidirectional LSTMs}
Bidirectional LSTMs (BiLSTMs) are sophisticated variants of LSTMs designed to
ehnance the ability to capture patterns in time series data and improve learning
long-term dependencies. Unlike LSTMs that only process data in a single
direction (from past to future), BiLSTMs utilise a more intuitive approach by
applying two LSTM models to the input data.  In the first round, the LSTM is
applied to the input data, and in the second round, it is applied to the
reversed input sequence. Furthermore, Tavakoli et al. (2019)
\cite{theperformanceoflstmandbilstminforcastingtimeseries}, concluded that
BiLSTMs reported better accuracies compared to regular LSTMs.

\begin{figure}[ht]
	\centering
  \includegraphics[width=0.8 \textwidth]{content/chapters/2_background/figures/bilstm_structure.png} 
  \caption{BiLSTM Structure. Reproduced from Du et al. (2020) \cite{du2020power}} 
  \label{fig:bilstm_structure}
\end{figure} %https://d2l.ai/chapter_recurrent-modern/lstm.html reproduced from

Figure \ref{fig:bilstm_structure} demonstrates the structure of a BiLSTM
network, showcasing the flow of data between the two parallel LSTM layers. The
first LSTM processes the input data in the forward direction, from $x_1$ to
$x_6$, while the other LSTM in the backwards direction from $x_6$ to
$x_1$, allowing the network to learn from past and future contexts. The forward LSTM
units are connected through weights $Wf_1$ and $Wf_2$, while the backward LSTM
units are connected through weights $Wb_1$ and $Wb_2$. By learning from
sequences in both directions, BiLSTMs are particularly effective in scenarios
where past and future contexts are crucial.