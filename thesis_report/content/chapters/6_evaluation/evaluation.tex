\clearpage
\chapter{Evaluation}


%talk about how the models often found it difficult to associate between ollie and kickflip since they are vastly different to shuvits

\section{Experiments}


\subsection{Choice of Optimiser}
%This might need to go in evaluation, and only mention it in the implementation
This study compared the results of Stochastic Gradient Descent (SGD) and Adam \cite{adam_paper} as
optimisation algorithms during training. The results suggest that SGD may be
more effective at reducing overfitting compared to Adam.
This improvement is illustrated in Figure \ref{fig:loss_graphs}, using the VGG-BiLSTM architecture.
While, Adam initially shows promise with good generalisation, it quickly
encounters a pitfall, where the validation loss begins to climb, indicating
overfitting. In contrast, the SGD-trained model exhibits a more stable
validation loss, likely due to its algorithmic stability and its capability to
achieve small generalisation errors as explained in the study by Hardt et al.
(2016) \cite{SGD_stability_paper}. The results observed with the VGG-BiLSTM
aligns with the insights discussed by Hardt et al. suggesting that
models trained using SGD are less vulnerable to overfitting.
\begin{figure}[ht!]
	\centering
	% First image (Adam)
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{content/chapters/5_Implementation/figures/Adam_optimiser.PNG}
		\caption{Training and Validation Loss using Adam}
		\label{fig:adam_loss}
	\end{subfigure}
	\hfill
	% Second image (SGD)
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{content/chapters/5_Implementation/figures/SGD_optimiser.PNG}
		\caption{Training and Validation Loss using SGD}
		\label{fig:sgd_loss}
	\end{subfigure}
	% Overall caption
	\caption{Model loss graphs for (a) Adam and (b) SGD optimisers.}
	\label{fig:loss_graphs}
\end{figure}
% talk about augmented and unaugmneted
% feature extractiona and without feature extraction
% talk about PCA improving accuracy on Resnet50

\subsection{The Effect of Data Augmentation}
This research, also compared the effects of Augmenting data before feeding it
into the sequence models. Table.. showcases the results




\section{Applicability In Real-Time applications}
For real-time applications like analysing skateboard events, the speed at which
data is processed is crucial. To evaluate the model's applicability in such
applications, this study measured the time taken to classify a single video for
each architecture.

%include results

The slow processing speeds outlined in Table is caused by the computational
expensive video analysis pipeline. This pipeline involves various steps: frame
extraction using optical flow, feature extraction with models like ResNet50 or
VGG16, dimensionality reduction using PCA and finally classifying the video from
the sequence model. While they are relatively slow, they are still applicable in
real-time events
% then look into times between tricks

%discussion

%conslusions from experiments, waht worked, what cost, training time
%show timings, list computer parts trained on
%compare models -which models do best
\section{Discussion}

\subsection{Challenges}
Trained models often encountered difficulty in differentiating between both the
ollie and kickflip compared to the pop shuvit. This challenge likely arises to
their shared visual characteristics. Both the ollie and the kickflip involve
common elements such as the initial pop of the skatebaord and the absence of
rotation on the y-axis, which distinguishes them to the pop shuvit. The
confusion matrix shown in Figure \ref{fig:resnet-lstm-confusion} presents the
ResNet-LSTM model exhibiting slightly better classification accuracy for pop
shuvits compared to ollies and kickflips.


\begin{figure}[h]
	\centering
  \includegraphics[width=0.7 \textwidth]{content/chapters/6_evaluation/figures/resnet-lstm-cm.png}
  \caption{ResNet50-LSTM Confusion Matrix}
  \label{fig:resnet-lstm-confusion}
\end{figure}