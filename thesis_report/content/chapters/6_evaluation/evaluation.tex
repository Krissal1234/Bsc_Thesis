\clearpage
\chapter{Evaluation}
\section{Model Training Specifications}
Due to the absence of a dedicated graphics card, training exclusively relied on
the CPU, featuring a Ryzen 5 3600 6-core processor, operating at a base clock
speed of 3.59 GHz. Despite lacking GPU acceleration, the Ryzen 5 3600 processor
reliably handled the training of several deep learning architectures and
experiments conducted.

\section{Experiments}
\subsection{Choice of Optimiser}
This study compared the results of Stochastic Gradient Descent (SGD) and Adam
\cite{adam_paper} as optimisation algorithms during training. The results
suggest that SGD may be more effective at reducing overfitting compared to Adam.
This improvement is illustrated in Figure \ref{fig:loss_graphs}, using
an iteration of the VGG-BiLSTM architecture. While, Adam initially shows promise with good
generalisation, it quickly encounters a pitfall, where the validation loss
begins to climb, indicating overfitting. In contrast, the SGD-trained model
exhibits a more stable validation loss, likely due to its algorithmic stability
and its capability to achieve small generalisation errors as explained in the
study by Hardt et al. (2016) \cite{SGD_stability_paper}. The results observed
with the VGG-BiLSTM aligns with the insights discussed by Hardt et al.
suggesting that models trained using SGD are less vulnerable to overfitting.

\begin{figure}[ht!]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{content/chapters/5_Implementation/figures/Adam_optimiser.PNG}
		\caption{Training and Validation Loss using Adam}
		\label{fig:adam_loss}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
		\includegraphics[width=\linewidth]{content/chapters/5_Implementation/figures/SGD_optimiser.PNG}
		\caption{Training and Validation Loss using SGD}
		\label{fig:sgd_loss}
	\end{subfigure}
	\caption{Model loss graphs for (a) Adam and (b) SGD optimisers.}
	\label{fig:loss_graphs}
\end{figure}


% talk about augmented and unaugmneted
% feature extractiona and without feature extraction
% talk about PCA improving accuracy on Resnet50

\subsection{The Effect of Data Augmentation} \label{data_augmentation_6}
%if I have time add augmentation x4
This research, also compared the effects of Augmenting data before feeding it
into the sequence models, as illustrated in Table \ref{tab:models_aug}.
Experiments revealed that each of the four models demonstrated improvements in
accuracies following the application of data augmentation on the input data.
Enhancements ranged from a 5\% increase in Model 3, to a 9\% increase in Models
1 and 4. On average, model accuracy increased by 7.75\% highlighting its
effectiveness in enhancing the model's ability to generalise on unseen data.
These results

\begin{table}[htbp]
    \centering
    \begin{tabularx}{\textwidth}{>{\RaggedRight}Xcccc}
        \toprule
        \textbf{Model} & \multicolumn{2}{c}{\textbf{Unenhanced}} & \multicolumn{2}{c}{\textbf{Augmented}} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        & {\textbf{Accuracy}} & {\textbf{Training Time}} & {\textbf{Accuracy}} & {\textbf{Training Time}} \\
        \midrule
        \textbf{1.  VGG16-LSTM} & 77\% & 00:07:47 & 86\% & 00:11:38 \\
        \textbf{2.  VGG16-BiLSTM} & 80\% & 00:07:45 & 88\% & 00:18:05  \\
        \textbf{3.  ResNet50-LSTM} & 75\%& 00:01:19 & 80\% & 00:02:19 \\
        \textbf{4.  ResNet50-BiLSTM} & 77\% & 00:01:41& 86\% & 00:03:01 \\
        \bottomrule
    \end{tabularx}
    \caption{Performance comparison of models with and without augmentation}
    \label{tab:models_aug}
\end{table}

%mention shorter training times due to less data

\subsection{The Effect of PCA}
Another experiment conducted, involved evaluating the impact of PCA on model
performance. The analysis compared VGG16-BiLSTM and ResNet50-BiLSTM as they were
the top-performing models from each category of pre-trained models, This
comparison focused on their accuracies before and after the application of PCA,
as well as differences in training times. To ensure fair results, both models
were trained with using the same augmented data, with features reduced to their
respective pre-calculated number of components discussed in Section
\ref{5_dimensionality_reduction}. Table \ref{tab:pca_effect} presents a
side-by-side comparison of these models with their training times along.

\begin{table}[htbp]
	\centering
	\begin{tabularx}{\textwidth}{>{\RaggedRight}Xcccc}
			\toprule
			\textbf{Model} & \multicolumn{2}{c}{\textbf{Pre-PCA}} & \multicolumn{2}{c}{\textbf{Post-PCA}} \\
			\cmidrule(lr){2-3} \cmidrule(lr){4-5}
			& {\textbf{Accuracy}} & {\textbf{Training Time}} & {\textbf{Accuracy}} & {\textbf{Training Time}} \\
			\midrule
			\textbf{VGG16-BiLSTM} & 58\% & 04:29:00 & 88\% & 00:18:05  \\
			\textbf{ResNet50-BiLSTM} & 33\% & 03:29:00 & 86\% & 00:03:01 \\
			\bottomrule
	\end{tabularx}
	\caption{Comparison of VGG16-BiLSTM and ResNet50-BiLSTM model performances before and after PCA implementation}
	\label{tab:pca_effect}
\end{table}

The application of PCA shows significant results, not only improving accuracies
but also reducing training times drastically. These results highlight the
benefits of applying dimensionality reduction to combat the 'curse of
dimensionality', often encountered with high-dimensional data spaces as noted in
Section \ref{4_dimensionality_reduction}. The observed improvements are a result
of the removal of redundant features in the dataset, further enhancing the
model's learning capabilities by allowing them to focus on the most informative
features.

%not going to test feature extraction because i think its out of scope, plus too many features so ill have to introduce pca which just makes it weirfd
%as ill have to stay calculating the number of components again ---ask
% \section{The Effect of Feature Extraction}
% The same sequence models, VGG-BiLSTM and ResNet50-BiLSTM, were further tested
% by comparing the effect the application of feature extraction and withou
% %Table


\subsection{Applicability In Real-Time applications}
For real-time applications like analysing skateboarding events, the speed at
which video data is processed and evaluated is crucial. To evaluate the model's
applicability in such applications, this study measured the time taken to
classify a single 2-second video at $\sim$30fps for each architecture.

\begin{table}[htbp]
	\centering
	\begin{tabular}{l c}
			\toprule
			\textbf{Model} & \textbf{Evaluation Time (ss:ms)} \\
			\midrule
			Model 1 (VGG16-LSTM) &  09:10\\
			Model 2 (VGG16-BiLSTM) &  09:90\\
			Model 3 (ResNet50-LSTM) &  08:20\\
			Model 4 (ResNet50-BiLSTM) & 9:00\\
			\bottomrule
	\end{tabular}
	\caption{Evaluation time (ss:mm) for skateboard trick classification models.}
	\label{tab:evaluation_time}
\end{table}
The slow processing speeds outlined in Table \ref{tab:evaluation_time} is caused
by the computational expensive video analysis pipeline required. This pipeline
involves various steps: frame extraction using optical flow, feature extraction
with models like ResNet50 or VGG16, dimensionality reduction using PCA and
finally classifying the video from the sequence model. While this pipeline
negatively affected evaluation times, it was responsible for achieving high
accuracies and significantly accelerating training time.

\section{Discussion}
%conslusions from experiments, what worked, what cost, training time
\subsection{Final Results}
%first write about table models_results, describe the best model, indicate that the model architectures can be found in appendix
%then i want to discuss the experiments results, compare with literature too, mention augmentation increased in this paper, pca in this paper etc..
% %then also
As shown in Table \ref{tab:model-summary}, the VGG-BiLSTM model emerged as the
top performer with a final accuracy of 88\%. This performance was significantly
enhanced through the various pre-processing techniques employed in the data
pipeline, which not only helped in improving accuracies but also in reducing
training times.

The integration of data augmentation was particularly beneficial as outlined in
Section \ref{data_augmentation_6}. By addressing the limitation of limited data
and artificially expanding the diversity of the training dataset through
transformation such as adjustments in brightness, slight rotations and zoom
factors, each model demonstrated a significant increase in performance.
% Table \ref{tab:models_results} presents the final model performance figures from
% the selected architecture groups. The best performing model architecture was the
% VGG16-BiLSTM, with an accuracy of 88\%. These models underwent many iterations
% of tuning to
%mention that we got these accuraccies with the application of data augmentation
%and also pca helping us with trainin time significantly but also with accuracies as mentioned in section **
%then after lightly brushing past the experiments conducted, begin comparing with Chens models,


\begin{table}[htbp]
	\centering
	\begin{tabularx}{\textwidth}{>{\RaggedRight}Xcc}
			\toprule
			\textbf{Model} & \textbf{Accuracy} & \textbf{Training Time} \\
			\midrule
			\textbf{1.  VGG16-LSTM} & 86\% & 00:11:38 \\
			\textbf{2.  VGG16-BiLSTM} & 88\% & 00:18:05 \\
			\textbf{3.  ResNet50-LSTM} & 80\% & 00:02:19 \\
			\textbf{4.  ResNet50-BiLSTM} & 86\% & 00:03:01 \\
			\bottomrule
	\end{tabularx}
	\caption{Performance of models after data augmentation}
	\label{tab:models_results}
\end{table}

\subsection{Classification observations}
%The reason it does not do so well with kickflips, is becuase some kickflip videos are filmed with the skater facing sideways, and it classifies them as shuvit, probaly because most shuvits are sideways
Trained models often encountered difficulty in differentiating between both the
ollie and kickflip compared to the pop shuvit. This challenge likely arises to
their shared visual characteristics. Both the ollie and the kickflip involve
common elements such as the initial pop of the skateboard and the absence of
rotation on the y-axis, which distinguishes them to the pop shuvit. The
confusion matrix shown in Figure \ref{fig:resnet-lstm-confusion} presents the
ResNet-LSTM model exhibiting slightly better classification accuracy for pop
shuvits compared to ollies and kickflips.

\begin{figure}[h]
	\centering
  \includegraphics[width=0.7 \textwidth]{content/chapters/6_evaluation/figures/resnet-lstm-cm.png}
  \caption{ResNet50-LSTM Confusion Matrix}
\label{fig:resnet-lstm-confusion}
\end{figure}

\section{Limitations}
This study encountered a significant limitation, due to the insufficient amount
of data available for training the models. The scarcity of this data constrained
the ability to train more robust and accurate models, potentially not allowing
them to capture the full variability of real-world scenarios. This limitation
presented several challenges
